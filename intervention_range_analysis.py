#!/usr/bin/env python3
"""
åŸºäºç°æœ‰åˆ†ææŠ¥å‘Šçš„å¹²é¢„èŒƒå›´åˆ†æè„šæœ¬
ä»å„ä¸ªå®éªŒæ–‡ä»¶å¤¹çš„analysis_report.mdä¸­æå–æ­£ç¡®ç‡æ•°æ®ï¼Œ
åˆ†æå¹²é¢„æ˜¯å¦è¶…å‡ºäº†åŸå§‹æ­£ç¡®ç‡çš„å˜åŒ–èŒƒå›´
åŒ…å«æ€»ä½“ã€æŒ‰å­¦ç§‘ã€æŒ‰éš¾åº¦ç­‰çº§çš„è¯¦ç»†åˆ†æ
"""

import os
import re
from typing import Dict, List, Tuple

def extract_accuracy_from_report(file_path: str) -> Dict:
    """ä»analysis_report.mdæ–‡ä»¶ä¸­æå–æ­£ç¡®ç‡æ•°æ®"""
    if not os.path.exists(file_path):
        return {}
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        result = {}
        
        # 1. æå–æ€»ä½“å‡†ç¡®ç‡
        pattern = r'\| intervention_gaussian_replace_mean0_std0 \| ([0-9.%]+) \([0-9/]+\) \| ([0-9.%]+) \([0-9/]+\) \| ([0-9.%]+) \([0-9/]+\) \| ([0-9.%]+) \([0-9/]+\) \|'
        match = re.search(pattern, content)
        
        if match:
            result['overall'] = {
                'NoThink': {
                    'original': float(match.group(1).rstrip('%')),
                    'intervention': float(match.group(2).rstrip('%'))
                },
                'Think': {
                    'original': float(match.group(3).rstrip('%')),
                    'intervention': float(match.group(4).rstrip('%'))
                }
            }
        
        # 2. æå–æŒ‰å­¦ç§‘çš„å‡†ç¡®ç‡ - ä¿®æ­£æ­£åˆ™è¡¨è¾¾å¼
        subject_pattern = r'\| ([^|]+?) \| \d+ \| ([0-9.%]+) \([0-9/]+\) \| ([0-9.%]+) \([0-9/]+\) \| [^|]+ \| ([0-9.%]+) \([0-9/]+\) \| ([0-9.%]+) \([0-9/]+\) \| [^|]+ \|'
        subjects_section = re.search(r'### intervention_gaussian_replace_mean0_std0 - æŒ‰å­¦ç§‘å‡†ç¡®ç‡.*?(?=###|##|$)', content, re.DOTALL)
        
        if subjects_section:
            result['subjects'] = {}
            subject_matches = list(re.finditer(subject_pattern, subjects_section.group(0)))
            
            for match in subject_matches:
                subject = match.group(1).strip()
                if subject != 'å­¦ç§‘' and not subject.startswith('---'):  # è·³è¿‡è¡¨å¤´å’Œåˆ†éš”çº¿
                    try:
                        result['subjects'][subject] = {
                            'NoThink': {
                                'original': float(match.group(2).rstrip('%')),
                                'intervention': float(match.group(3).rstrip('%'))
                            },
                            'Think': {
                                'original': float(match.group(4).rstrip('%')),
                                'intervention': float(match.group(5).rstrip('%'))
                            }
                        }
                    except:
                        pass  # è·³è¿‡æ— æ•ˆè¡Œ
        
        # 3. æå–æŒ‰éš¾åº¦ç­‰çº§çš„å‡†ç¡®ç‡ - ä¿®æ­£æ­£åˆ™è¡¨è¾¾å¼
        level_pattern = r'\| Level (\d+) \| \d+ \| ([0-9.%]+) \([0-9/]+\) \| ([0-9.%]+) \([0-9/]+\) \| [^|]+ \| ([0-9.%]+) \([0-9/]+\) \| ([0-9.%]+) \([0-9/]+\) \| [^|]+ \|'
        levels_section = re.search(r'### intervention_gaussian_replace_mean0_std0 - æŒ‰éš¾åº¦ç­‰çº§.*?(?=###|##|$)', content, re.DOTALL)
        
        if levels_section:
            result['levels'] = {}
            level_matches = list(re.finditer(level_pattern, levels_section.group(0)))
            
            for match in level_matches:
                level = f"Level {match.group(1)}"
                try:
                    result['levels'][level] = {
                        'NoThink': {
                            'original': float(match.group(2).rstrip('%')),
                            'intervention': float(match.group(3).rstrip('%'))
                        },
                        'Think': {
                            'original': float(match.group(4).rstrip('%')),
                            'intervention': float(match.group(5).rstrip('%'))
                        }
                    }
                except:
                    pass  # è·³è¿‡æ— æ•ˆè¡Œ
        
        return result
        
    except Exception as e:
        print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return {}

def analyze_category_data(all_data: Dict, category: str, category_name: str):
    """åˆ†ææŸä¸ªåˆ†ç±»çš„æ•°æ®ï¼ˆå­¦ç§‘æˆ–éš¾åº¦ç­‰çº§ï¼‰"""
    print(f"\nğŸ” {category_name}åˆ†æ:")
    
    # æ”¶é›†æ‰€æœ‰è¯¥åˆ†ç±»çš„åŸå§‹æ­£ç¡®ç‡
    category_stats = {}
    
    for exp_name, exp_data in all_data.items():
        if category not in exp_data:
            continue
            
        for item_name, item_data in exp_data[category].items():
            if item_name not in category_stats:
                category_stats[item_name] = {
                    'NoThink': {'originals': [], 'interventions': []},
                    'Think': {'originals': [], 'interventions': []}
                }
            
            for mode in ['NoThink', 'Think']:
                if mode in item_data:
                    category_stats[item_name][mode]['originals'].append(item_data[mode]['original'])
                    category_stats[item_name][mode]['interventions'].append(item_data[mode]['intervention'])
    
    # åˆ†ææ¯ä¸ªç±»åˆ«é¡¹
    significant_items = []
    
    print(f"{'ç±»åˆ«':<20} {'æ¨¡å¼':<8} {'åŸå§‹èŒƒå›´':<15} {'å¹²é¢„èŒƒå›´':<15} {'è¶…å‡ºèŒƒå›´çš„å®éªŒ'}")
    print("-" * 80)
    
    for item_name in sorted(category_stats.keys()):
        item_data = category_stats[item_name]
        
        for mode in ['NoThink', 'Think']:
            originals = item_data[mode]['originals']
            interventions = item_data[mode]['interventions']
            
            if not originals:
                continue
                
            orig_min, orig_max = min(originals), max(originals)
            
            # æ£€æŸ¥å“ªäº›å¹²é¢„è¶…å‡ºèŒƒå›´
            outside_experiments = []
            for i, (exp_name, exp_data) in enumerate(all_data.items()):
                if category in exp_data and item_name in exp_data[category]:
                    if mode in exp_data[category][item_name]:
                        inter_val = exp_data[category][item_name][mode]['intervention']
                        if inter_val < orig_min or inter_val > orig_max:
                            short_name = exp_name.replace('math_intervention_results_', '').replace('math_intervention_results', 'baseline')
                            outside_experiments.append(short_name)
            
            outside_str = ", ".join(outside_experiments) if outside_experiments else "æ— "
            if outside_experiments:
                significant_items.append(f"{item_name}-{mode}")
            
            print(f"{item_name:<20} {mode:<8} {orig_min:.1f}%-{orig_max:.1f}%{'':<3} {min(interventions):.1f}%-{max(interventions):.1f}%{'':<3} {outside_str}")
    
    if significant_items:
        print(f"\nğŸ“ˆ å‘ç° {len(significant_items)} ä¸ª{category_name}ç±»åˆ«æœ‰æ˜¾è‘—å¹²é¢„æ•ˆæœ:")
        for item in significant_items:
            print(f"    â€¢ {item}")
    else:
        print(f"\nğŸ“ˆ æ‰€æœ‰{category_name}ç±»åˆ«çš„å¹²é¢„æ•ˆæœéƒ½åœ¨åŸå§‹æ­£ç¡®ç‡èŒƒå›´å†…")

def analyze_experiments():
    """åˆ†ææ‰€æœ‰å®éªŒç»“æœ"""
    
    # å®šä¹‰å®éªŒç›®å½•
    experiment_dirs = [
        'math_intervention_results',
        'math_intervention_results_nothink_1epoch_42nodes',
        'math_intervention_results_nothink_1epoch_42nodes_greedy',
        'math_intervention_results_think_1epoch',
        'math_intervention_results_think_1epoch_43nodes',
        'math_intervention_results_think_1epoch_43nodes_greedy',
        'math_intervention_results_think_bynode_1epoch'
    ]
    
    all_data = {}
    
    # æ”¶é›†æ‰€æœ‰å®éªŒæ•°æ®
    for exp_dir in experiment_dirs:
        report_path = os.path.join(exp_dir, 'analysis_report.md')
        data = extract_accuracy_from_report(report_path)
        if data:
            all_data[exp_dir] = data
            print(f"âœ“ æˆåŠŸè¯»å– {exp_dir}")
        else:
            print(f"âœ— æ— æ³•è¯»å– {exp_dir}")
    
    if not all_data:
        print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„å®éªŒæ•°æ®ï¼")
        return
    
    # 1. æ€»ä½“åˆ†æ
    nothink_originals = []
    think_originals = []
    
    for exp_name, data in all_data.items():
        if 'overall' in data:
            if 'NoThink' in data['overall']:
                nothink_originals.append(data['overall']['NoThink']['original'])
            if 'Think' in data['overall']:
                think_originals.append(data['overall']['Think']['original'])
    
    # è®¡ç®—åŸå§‹æ­£ç¡®ç‡çš„èŒƒå›´
    nothink_min = min(nothink_originals) if nothink_originals else 0
    nothink_max = max(nothink_originals) if nothink_originals else 0
    think_min = min(think_originals) if think_originals else 0
    think_max = max(think_originals) if think_originals else 0
    
    print("\n" + "="*80)
    print("å¹²é¢„æ•ˆæœè¯¦ç»†èŒƒå›´åˆ†ææŠ¥å‘Š")
    print("="*80)
    
    print(f"\nğŸ“Š æ€»ä½“æ­£ç¡®ç‡èŒƒå›´ç»Ÿè®¡:")
    print(f"  NoThinkæ¨¡å¼: {nothink_min:.2f}% - {nothink_max:.2f}% (å˜åŒ–èŒƒå›´: {nothink_max - nothink_min:.2f}%)")
    print(f"  Thinkæ¨¡å¼:   {think_min:.2f}% - {think_max:.2f}% (å˜åŒ–èŒƒå›´: {think_max - think_min:.2f}%)")
    
    print(f"\nğŸ” æ€»ä½“å¹²é¢„æ•ˆæœåˆ†æ:")
    print(f"{'å®éªŒåç§°':<45} {'NoThinkåŸå§‹':<12} {'NoThinkå¹²é¢„':<12} {'å¹²é¢„æ•ˆæœ':<15} {'ThinkåŸå§‹':<12} {'Thinkå¹²é¢„':<12} {'å¹²é¢„æ•ˆæœ':<15}")
    print("-" * 140)
    
    significant_interventions = []
    
    for exp_name, data in all_data.items():
        if 'overall' not in data:
            continue
            
        nothink_orig = data['overall'].get('NoThink', {}).get('original', 0)
        nothink_inter = data['overall'].get('NoThink', {}).get('intervention', 0)
        think_orig = data['overall'].get('Think', {}).get('original', 0)
        think_inter = data['overall'].get('Think', {}).get('intervention', 0)
        
        # åˆ¤æ–­å¹²é¢„æ˜¯å¦è¶…å‡ºåŸå§‹èŒƒå›´
        nothink_outside = nothink_inter < nothink_min or nothink_inter > nothink_max if nothink_inter != 0 else False
        think_outside = think_inter < think_min or think_inter > think_max if think_inter != 0 else False
        
        nothink_effect = "è¶…å‡ºèŒƒå›´!" if nothink_outside else "èŒƒå›´å†…"
        think_effect = "è¶…å‡ºèŒƒå›´!" if think_outside else "èŒƒå›´å†…"
        
        if nothink_outside or think_outside:
            significant_interventions.append(exp_name)
        
        # ç®€åŒ–å®éªŒåç§°æ˜¾ç¤º
        short_name = exp_name.replace('math_intervention_results_', '').replace('math_intervention_results', 'baseline')
        
        print(f"{short_name:<45} {nothink_orig:<12.2f} {nothink_inter:<12.2f} {nothink_effect:<15} {think_orig:<12.2f} {think_inter:<12.2f} {think_effect:<15}")
    
    # 2. æŒ‰å­¦ç§‘åˆ†æ
    if any('subjects' in data for data in all_data.values()):
        analyze_category_data(all_data, 'subjects', 'å­¦ç§‘')
    
    # 3. æŒ‰éš¾åº¦ç­‰çº§åˆ†æ
    if any('levels' in data for data in all_data.values()):
        analyze_category_data(all_data, 'levels', 'éš¾åº¦ç­‰çº§')
    
    print("\n" + "="*80)
    print("ğŸ“ˆ æ€»ä½“å¹²é¢„æ•ˆæœæ€»ç»“:")
    
    if significant_interventions:
        print(f"  å‘ç° {len(significant_interventions)} ä¸ªå®éªŒçš„æ€»ä½“å¹²é¢„æ•ˆæœè¶…å‡ºäº†åŸå§‹æ­£ç¡®ç‡å˜åŒ–èŒƒå›´:")
        for exp in significant_interventions:
            short_name = exp.replace('math_intervention_results_', '').replace('math_intervention_results', 'baseline')
            print(f"    â€¢ {short_name}")
    else:
        print("  æ‰€æœ‰å®éªŒçš„æ€»ä½“å¹²é¢„æ•ˆæœéƒ½åœ¨åŸå§‹æ­£ç¡®ç‡çš„å˜åŒ–èŒƒå›´å†…ï¼Œè¡¨æ˜å¹²é¢„å½±å“å¯èƒ½ä¸æ˜¾è‘—")
    
    print(f"\nğŸ’¡ è§£é‡Š:")
    print(f"  - ç”±äºé‡‡æ ·éšæœºæ€§ï¼Œä¸åŒå®éªŒçš„åŸå§‹æ­£ç¡®ç‡ä¼šæœ‰å˜åŒ–")
    print(f"  - å¦‚æœå¹²é¢„åæ­£ç¡®ç‡è¶…å‡ºäº†åŸå§‹æ­£ç¡®ç‡çš„æœ€å¤§æœ€å°å€¼èŒƒå›´ï¼Œå¯èƒ½è¡¨æ˜å¹²é¢„æœ‰æ˜¾è‘—å½±å“")
    print(f"  - åœ¨èŒƒå›´å†…çš„å˜åŒ–å¯èƒ½ä¸»è¦ç”±é‡‡æ ·éšæœºæ€§é€ æˆ")
    print(f"  - æŒ‰å­¦ç§‘å’Œéš¾åº¦ç­‰çº§çš„åˆ†æèƒ½å¤Ÿå‘ç°æ›´ç»†ç²’åº¦çš„å¹²é¢„æ•ˆæœ")
    
    print("\n" + "="*80)

if __name__ == "__main__":
    analyze_experiments() 